{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Objectif:\n",
        "Comprendre l'ensemble de données et le nettoyage (si nécessaire).\n",
        "Créez des modèles de classification pour prédire si le type de cancer est malin ou bénin.\n",
        "Ajustez également les hyperparamètres et comparez les mesures d'évaluation de divers algorithmes de classification."
      ],
      "metadata": {
        "id": "T4AJexJvF1ZW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPzIzmjh_iEH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "etZWcyrXChV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "twGv2F1_CmoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/gdrive/My Drive/Breast_Cancer_Dataset'\n"
      ],
      "metadata": {
        "id": "BlTyQpfTCsCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Charger le dataset\n",
        "data = pd.read_csv(path + '/breast-cancer.csv')\n"
      ],
      "metadata": {
        "id": "agD08O4R_qYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Explorer les données\n",
        "#print(data.head())\n",
        "#print(data.info())\n",
        "#print(data.describe())\n"
      ],
      "metadata": {
        "id": "nKES7hNZBSI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Id\n",
        "data.drop('id', axis=1, inplace=True)  # Supprimer la colonne 'id'"
      ],
      "metadata": {
        "id": "Kzv33YXqTcku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data['diagnosis'].unique())\n"
      ],
      "metadata": {
        "id": "cTCrQux86pKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compter les occurrences de chaque valeur dans la colonne \"diagnosis\"\n",
        "plt.figure(figsize=(6, 4))\n",
        "counts = data['diagnosis'].value_counts()\n",
        "\n",
        "# Créer un diagramme en barres\n",
        "plt.bar(counts.index, counts.values, color=['red', 'green'])\n",
        "\n",
        "# Ajouter des titres et des étiquettes d'axe\n",
        "plt.title('Distribution des diagnostics')\n",
        "plt.xlabel('Diagnostic')\n",
        "plt.ylabel('Nombre de patients')\n",
        "plt.legend(labels=['Benign', 'Malignant'])\n",
        "\n",
        "# Afficher le diagramme\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "y5BmNyDi8GvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Séparer les variables indépendantes (X) et dépendantes (y)\n",
        "X = data.drop('diagnosis', axis=1)\n",
        "y = data['diagnosis']"
      ],
      "metadata": {
        "id": "c1i34xM2c_jZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prétraiter les données\n",
        "# Encoder les étiquettes en valeurs binaires (0 et 1)\n",
        "labelencoder = LabelEncoder()\n",
        "y = labelencoder.fit_transform(y)\n",
        "# Afficher les valeurs uniques des étiquettes encodées (pour vérifier qu'on a bien 0 et 1)\n",
        "print(\"labels after encoding are: \", np.unique(y))#  'M': 0, 'B': 1\n",
        "#data['diagnosis'] = data['diagnosis'].map({'M': 1, 'B': 0})  # Transformer la colonne 'diagnosis' en valeurs binaires"
      ],
      "metadata": {
        "id": "Lo_8h7Qv_z7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remplacer les valeurs manquantes par la moyenne des valeurs de la colonne correspondante\n",
        "data.fillna(data.mean(numeric_only=True), inplace=True)\n"
      ],
      "metadata": {
        "id": "jqil50uHkbSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normaliser les données en utilisant MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X)\n",
        "X = scaler.transform(X)"
      ],
      "metadata": {
        "id": "duo0--e1VHoj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Diviser les données en ensembles d'entraînement et de test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "78vKo9kh_7Sn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normaliser les données\n",
        "#scaler = StandardScaler()\n",
        "#X_train = scaler.fit_transform(X_train)\n",
        "#X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "p_vgITaMAAq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(64, activation='relu', input_shape=(30,)),\n",
        "  tf.keras.layers.Dense(32, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "iO8JjBXXwUdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpretation du Model**\n",
        "Ce code définit un modèle de réseau neuronal séquentiel à l'aide de l'API Keras de TensorFlow. Le modèle comporte trois couches entièrement connectées, avec 64 neurones dans la couche d'entrée, 32 neurones dans la couche cachée et 1 neurone dans la couche de sortie. La fonction d'activation utilisée à la fois dans les couches d'entrée et cachée est ReLU (unité linéaire rectifiée), qui est couramment utilisée dans les réseaux de neurones.\n",
        "\n",
        "La couche d'entrée a une forme d'entrée de (30,), ce qui signifie que le modèle attend des données d'entrée avec 30 entités. La couche de sortie a un seul neurone avec une fonction d'activation sigmoïde, ce qui est approprié pour les problèmes de classification binaire.\n",
        "\n",
        "Le modèle comprend également une couche d'abandon avec un taux de 0,2, qui abandonne de manière aléatoire 20 % des unités d'entrée pendant l'entraînement pour aider à prévenir le surajustement."
      ],
      "metadata": {
        "id": "3gG6zIhdzOQd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from keras.layers.attention.multi_head_attention import activation\n",
        "#model=Sequential()\n",
        "#model.add(Dense(16,input_dim=30,activation='relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "#model.add(Dense(1))\n",
        "#model.add(Activation('sigmoid'))\n",
        "\n"
      ],
      "metadata": {
        "id": "dXHPLfL3fLGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiler le modèle\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "v3Uw-Dx0lB_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "wOQut9xHWKyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entraîner le modèle\n",
        "history = model.fit(X_train, y_train,verbose=1, epochs=100,batch_size=64, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "id": "2dvXZoolAWt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"!pip install flask\n",
        "!pip install tensorflow-serving-api\"\"\"\n"
      ],
      "metadata": {
        "id": "2_PlaHifDGso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"# Exporter le modèle\n",
        "export_path = path \n",
        "tf.saved_model.save(model, export_path)\"\"\""
      ],
      "metadata": {
        "id": "E6Ek1SQYBGLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!tensorflow_model_server --port=8500 --rest_api_port=8501 --model_name=model --model_base_path=path\n",
        "\n"
      ],
      "metadata": {
        "id": "w--GKsrLBY7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Évaluer la performance du modèle sur l'ensemble de test\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print('Test accuracy: {:.2f}%'.format(test_acc*100))"
      ],
      "metadata": {
        "id": "NrxiTvC2AaFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Évaluer la performance du modèle sur l'ensemble de test\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "epochs=range(1,len(loss) + 1)\n",
        "plt.plot(epochs,loss,'y',label='Training loss')\n",
        "plt.plot(epochs,val_loss,'b',label='Validation loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "acc=history.history['accuracy'] #Usage de Perf\n",
        "val_acc=history.history['val_accuracy'] #Usage de Val\n",
        "plt.plot(epochs,loss,'r',label='Training acc')\n",
        "plt.plot(epochs,val_loss,'g',label='Validation acc')\n",
        "plt.title('Training and Validation acc')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WS-IphLLW45M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=model.predict(X_test)\n",
        "y_pred=(y_pred > 0.5)\n",
        "\n",
        "#Matrice de Confusion\n",
        "cm=confusion_matrix(y_test, y_pred)\n",
        "\n",
        "sns.heatmap(cm, annot=True)"
      ],
      "metadata": {
        "id": "ghatpxIoZdB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Enregistrer le modèle au format H5\n",
        "#model.save('model.h5')"
      ],
      "metadata": {
        "id": "9yaIXO12LXei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "test_data1 = np.array([[13.08,15.71,85.63,520,0.1075,0.127,0.04568,0.0311,0.1967,0.06811,0.1852,0.7477,1.383,14.67,0.004097,0.01898,0.01698,0.00649,0.01678,0.002425,14.5,20.49,96.09,630.5,0.1312,0.2776,0.189,0.07283,0.3184,0.08183]])\n",
        "\n",
        "#test_data=np.array[[13.08,15.71,85.63,520,0.1075,0.127,0.04568,0.0311,0.1967,0.06811,0.1852,0.7477,1.383,14.67,0.004097,0.01898,0.01698,0.00649,0.01678,0.002425,14.5,20.49,96.09,630.5,0.1312,0.2776,0.189,0.07283,0.3184,0.08183]]\n",
        "test_data0 = np.array([[ 18.0, 100.0, 900.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2.0, 2.1, 2.2, 2.3, 2.4, 2.5, 2.6, 2.7]])\n"
      ],
      "metadata": {
        "id": "ioGhIzRmEhV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction1 = model.predict(test_data1)\n",
        "prediction0 = model.predict(test_data0)\n",
        "\n",
        "print(prediction1,prediction0)\n"
      ],
      "metadata": {
        "id": "qRVMHx6tElC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans ce code, nous avons d'abord chargé le dataset et séparé les variables indépendantes (X) et dépendantes (y). Ensuite, nous avons normalisé les données à l'aide de la classe StandardScaler de scikit-learn.\n",
        "\n",
        "Nous avons ensuite créé un modèle de réseau de neurones séquentiel avec trois couches : une couche d'entrée avec 64 neurones (pour correspondre au nombre de variables indépendantes), une couche cachée avec 32 neurones et une fonction d'activation ReLU, et une couche de sortie avec une fonction d'activation sigmoïde pour prédire la probabilité de cancer malin. Nous avons compilé le modèle avec une fonction de perte binary_crossentropy et une métrique d'accuracy.\n",
        "\n",
        "Nous avons ensuite entraîné le modèle pendant 100 époques sur l'ensemble d'entraînement, en utilisant l'ensemble de test comme ensemble de validation. Enfin, nous avons évalué la performance du modèle sur l'ensemble de test à l'aide de la méthode evaluate."
      ],
      "metadata": {
        "id": "n9T1d3vaAmY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"%%writefile app.py\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "MpdTa1IxMktT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"!export FLASK_APP=app.py\n",
        "!flask run --port 5000\"\"\""
      ],
      "metadata": {
        "id": "gug0GUV9HETM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}